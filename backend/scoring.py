#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è‡ªåŠ¨è¯„åˆ†ç³»ç»Ÿ
æ”¯æŒé€‰æ‹©é¢˜ã€ç®€ç­”é¢˜å’Œç¼–ç¨‹é¢˜çš„è‡ªåŠ¨è¯„åˆ†
"""

import json
import os
import re
import subprocess
import tempfile
from typing import Any, Dict, List, Tuple

import requests


class ScoringSystem:
    """è¯„åˆ†ç³»ç»Ÿ"""

    def __init__(self):
        # ä»æ•°æ®åº“è·å–AI APIé…ç½®
        self.api_key = None
        self.api_url = None
        self.model = None
        self.ai_scoring_enabled = False
        self._load_config_from_db()

        # å…³é”®è¯æƒé‡é…ç½®
        self.keyword_weights = {
            "high": 3,  # é«˜æƒé‡å…³é”®è¯
            "medium": 2,  # ä¸­æƒé‡å…³é”®è¯
            "low": 1,  # ä½æƒé‡å…³é”®è¯
        }

    def _load_config_from_db(self):
        """ä»æ•°æ®åº“åŠ è½½AIé…ç½®"""
        try:
            # å¯¼å…¥è¿™é‡Œè€Œä¸æ˜¯åœ¨æ–‡ä»¶é¡¶éƒ¨ï¼Œé¿å…å¾ªç¯å¯¼å…¥
            from flask import current_app, has_app_context
            from models import ApiProvider, SystemConfig

            # æ£€æŸ¥æ˜¯å¦åœ¨åº”ç”¨ä¸Šä¸‹æ–‡ä¸­
            if not has_app_context():
                print("ä¸åœ¨Flaskåº”ç”¨ä¸Šä¸‹æ–‡ä¸­ï¼ŒAIè¯„åˆ†å°†ä½¿ç”¨å…³é”®è¯åŒ¹é…")
                return

            # æ£€æŸ¥AIè¯„åˆ†æ˜¯å¦å¯ç”¨
            ai_scoring_config = SystemConfig.query.filter_by(
                config_key="aiScoringEnabled"
            ).first()
            if ai_scoring_config:
                self.ai_scoring_enabled = (
                    ai_scoring_config.config_value.lower() == "true"
                )
            else:
                # å¦‚æœæ²¡æœ‰é…ç½®ï¼Œé»˜è®¤å¯ç”¨ï¼ˆå‘åå…¼å®¹ï¼‰
                self.ai_scoring_enabled = True
                print("æœªæ‰¾åˆ°AIè¯„åˆ†é…ç½®ï¼Œé»˜è®¤å¯ç”¨")

            if not self.ai_scoring_enabled:
                print("AIè¯„åˆ†å·²ç¦ç”¨ï¼Œå°†ä½¿ç”¨å…³é”®è¯åŒ¹é…å¤‡ç”¨æ–¹æ¡ˆ")
                return

            # è·å–å½“å‰æ¿€æ´»ä¸”éªŒè¯é€šè¿‡çš„APIæä¾›å•†
            active_provider = ApiProvider.query.filter_by(
                is_active=True, is_verified=True
            ).first()

            if active_provider:
                self.api_key = active_provider.api_key
                self.api_url = active_provider.api_url
                self.model = active_provider.default_model
                print(
                    f"ğŸ¤– AIè¯„åˆ†é…ç½®åŠ è½½æˆåŠŸ: {active_provider.display_name} - {self.model}"
                )

                # éªŒè¯APIæ˜¯å¦çœŸæ­£å¯ç”¨
                if not self._verify_api_connection():
                    print("âš ï¸  APIè¿æ¥éªŒè¯å¤±è´¥ï¼ŒAIè¯„åˆ†å°†ä½¿ç”¨åŸºæœ¬è¯„åˆ†ç»“æ„")
                    self.ai_scoring_enabled = False
                    self.api_key = None
                    self.api_url = None
                    self.model = None
            else:
                print("âš ï¸  æœªæ‰¾åˆ°æ¿€æ´»ä¸”éªŒè¯çš„APIæä¾›å•†ï¼ŒAIè¯„åˆ†å°†ä½¿ç”¨åŸºæœ¬è¯„åˆ†ç»“æ„")
                self.ai_scoring_enabled = False

        except Exception as e:
            print(f"âŒ ä»æ•°æ®åº“åŠ è½½AIé…ç½®å¤±è´¥: {str(e)}")
            # å‘ç”Ÿé”™è¯¯æ—¶é»˜è®¤ç¦ç”¨AIè¯„åˆ†ï¼Œä½¿ç”¨å…³é”®è¯åŒ¹é…
            self.ai_scoring_enabled = False

    def _verify_api_connection(self):
        """éªŒè¯APIè¿æ¥æ˜¯å¦å¯ç”¨"""
        try:
            if not self.api_key or not self.api_url:
                return False

            # å‘é€ä¸€ä¸ªç®€å•çš„æµ‹è¯•è¯·æ±‚
            test_prompt = "æµ‹è¯•è¿æ¥"
            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json",
            }

            data = {
                "model": self.model,
                "messages": [{"role": "user", "content": test_prompt}],
                "max_tokens": 10,
                "temperature": 0.1,
            }

            response = requests.post(
                self.api_url, headers=headers, json=data, timeout=5  # 5ç§’è¶…æ—¶
            )

            if response.status_code == 200:
                print("âœ… APIè¿æ¥éªŒè¯æˆåŠŸ")
                return True
            else:
                print(f"âŒ APIè¿æ¥éªŒè¯å¤±è´¥: HTTP {response.status_code}")
                return False

        except Exception as e:
            print(f"âŒ APIè¿æ¥éªŒè¯å¼‚å¸¸: {str(e)}")
            return False

    def calculate_scores_for_instance(
        self, instance_id: int, questions: List[Dict], answers: Dict[str, str]
    ) -> Dict[str, Any]:
        """è®¡ç®—è€ƒè¯•å®ä¾‹æ€»åˆ†å’Œè¯¦ç»†åˆ†æ•°"""
        print(f"å¼€å§‹è®¡ç®—è€ƒè¯•å®ä¾‹ {instance_id} çš„åˆ†æ•°ï¼Œå…± {len(questions)} é“é¢˜ç›®")
        return self._calculate_scores_internal(
            questions, answers, instance_id, is_instance=True
        )

    def calculate_scores(
        self, exam_id: int, questions: List[Dict], answers: Dict[str, str]
    ) -> Dict[str, Any]:
        """è®¡ç®—è€ƒè¯•æ€»åˆ†å’Œè¯¦ç»†åˆ†æ•°"""
        print(f"å¼€å§‹è®¡ç®—è€ƒè¯• {exam_id} çš„åˆ†æ•°ï¼Œå…± {len(questions)} é“é¢˜ç›®")
        return self._calculate_scores_internal(
            questions, answers, exam_id, is_instance=False
        )

    def _calculate_scores_internal(
        self,
        questions: List[Dict],
        answers: Dict[str, str],
        exam_or_instance_id: int,
        is_instance: bool = False,
    ) -> Dict[str, Any]:
        """å†…éƒ¨è¯„åˆ†æ–¹æ³•"""
        total_score = 0
        max_score = 0
        subject_scores = {}
        difficulty_scores = {}
        cognitive_scores = {}
        question_scores = []

        entity_type = "è€ƒè¯•å®ä¾‹" if is_instance else "è€ƒè¯•"
        print(
            f"å¼€å§‹è®¡ç®—{entity_type} {exam_or_instance_id} çš„åˆ†æ•°ï¼Œå…± {len(questions)} é“é¢˜ç›®"
        )

        for i, question in enumerate(questions):
            # è·å–é¢˜ç›®IDï¼Œå°è¯•å¤šç§å¯èƒ½çš„å­—æ®µå
            question_id = str(
                question.get("id", question.get("question_id", str(i + 1)))
            )
            student_answer = answers.get(
                question_id, answers.get(str(question.get("id", "")), "")
            )

            print(f"é¢˜ç›® {i+1} (ID: {question_id}): å­¦ç”Ÿç­”æ¡ˆé•¿åº¦ {len(student_answer)}")

            # è®¡ç®—å•é¢˜åˆ†æ•°
            question_score, max_question_score = self._score_single_question(
                question, student_answer
            )

            print(f"é¢˜ç›® {i+1} å¾—åˆ†: {question_score}/{max_question_score}")

            total_score += question_score
            max_score += max_question_score

            # è®°å½•é¢˜ç›®åˆ†æ•°
            question_scores.append(
                {
                    "question_id": question_id,
                    "score": question_score,
                    "max_score": max_question_score,
                    "percentage": (
                        (question_score / max_question_score * 100)
                        if max_question_score > 0
                        else 0
                    ),
                    "student_answer": (
                        student_answer[:100] + "..."
                        if len(student_answer) > 100
                        else student_answer
                    ),
                    "question_type": question.get(
                        "type_key", question.get("question_type", "unknown")
                    ),
                }
            )

            # æŒ‰å­¦ç§‘ç»Ÿè®¡
            subject = question.get("subject", question.get("subject_key", "unknown"))
            if subject not in subject_scores:
                subject_scores[subject] = {"score": 0, "max_score": 0}
            subject_scores[subject]["score"] += question_score
            subject_scores[subject]["max_score"] += max_question_score

            # æŒ‰éš¾åº¦ç»Ÿè®¡
            difficulty = question.get(
                "difficulty", question.get("difficulty_key", "unknown")
            )
            if difficulty not in difficulty_scores:
                difficulty_scores[difficulty] = {"score": 0, "max_score": 0}
            difficulty_scores[difficulty]["score"] += question_score
            difficulty_scores[difficulty]["max_score"] += max_question_score

            # æŒ‰è®¤çŸ¥å±‚çº§ç»Ÿè®¡
            cognitive = question.get(
                "cognitive_level", question.get("cognitive_key", "unknown")
            )
            if cognitive not in cognitive_scores:
                cognitive_scores[cognitive] = {"score": 0, "max_score": 0}
            cognitive_scores[cognitive]["score"] += question_score
            cognitive_scores[cognitive]["max_score"] += max_question_score

        # è®¡ç®—ç™¾åˆ†æ¯”åˆ†æ•°
        percentage_score = (total_score / max_score * 100) if max_score > 0 else 0

        # è®¡ç®—ç­‰çº§
        grade = self._calculate_grade(percentage_score)

        # è®¡ç®—å­¦ç§‘ç™¾åˆ†æ¯”
        subject_percentages = {}
        for subject, scores in subject_scores.items():
            if scores["max_score"] > 0:
                subject_percentages[subject] = (
                    scores["score"] / scores["max_score"] * 100
                )
            else:
                subject_percentages[subject] = 0

        print(f"æœ€ç»ˆè®¡ç®—ç»“æœ: æ€»åˆ† {total_score}/{max_score} ({percentage_score:.2f}%)")

        # æ›´æ–°æ•°æ®åº“ä¸­çš„Answerè®°å½•
        self._update_answer_scores(exam_or_instance_id, question_scores, is_instance)

        return {
            "total_score": round(total_score, 2),
            "max_score": round(max_score, 2),
            "percentage_score": round(percentage_score, 2),
            "grade": grade,
            "subject_scores": subject_percentages,
            "difficulty_scores": difficulty_scores,
            "cognitive_scores": cognitive_scores,
            "question_scores": question_scores,
            "summary": self._generate_summary(percentage_score, subject_percentages),
            "debug_info": {
                "questions_count": len(questions),
                "answers_count": len(answers),
                "calculated_questions": len(question_scores),
            },
        }

    def _score_single_question(
        self, question: Dict, student_answer: str
    ) -> Tuple[float, float]:
        """è®¡ç®—å•ä¸ªé¢˜ç›®çš„åˆ†æ•°"""
        question_type = question.get("type_key", question.get("question_type", ""))
        max_score = float(question.get("points", 1))

        if not student_answer or not student_answer.strip():
            return 0.0, max_score

        # æ ‡å‡†åŒ–é¢˜ç›®ç±»å‹
        if question_type in ["multiple_choice", "é€‰æ‹©é¢˜"]:
            return self._score_multiple_choice(question, student_answer, max_score)
        elif question_type in ["short_answer", "ç®€ç­”é¢˜"]:
            return self._score_short_answer(question, student_answer, max_score)
        elif question_type in ["programming", "ç¼–ç¨‹é¢˜"]:
            return self._score_programming(question, student_answer, max_score)
        else:
            # é»˜è®¤æŒ‰ç®€ç­”é¢˜å¤„ç†
            return self._score_short_answer(question, student_answer, max_score)

    def _score_multiple_choice(
        self, question: Dict, student_answer: str, max_score: float
    ) -> Tuple[float, float]:
        """è¯„åˆ†é€‰æ‹©é¢˜"""
        correct_answer = question.get("correct_answer", "")

        # æ ‡å‡†åŒ–ç­”æ¡ˆæ ¼å¼
        student_clean = student_answer.strip().lower()
        correct_clean = correct_answer.strip().lower()

        # ç›´æ¥æ¯”è¾ƒ
        if student_clean == correct_clean:
            return max_score, max_score

        # å°è¯•æ¯”è¾ƒé€‰é¡¹å†…å®¹ï¼ˆå¦‚æœå­¦ç”Ÿç­”æ¡ˆæ˜¯é€‰é¡¹å†…å®¹è€Œä¸æ˜¯é€‰é¡¹å­—æ¯ï¼‰
        options = question.get("options", [])
        if options:
            # æŸ¥æ‰¾å­¦ç”Ÿç­”æ¡ˆå¯¹åº”çš„é€‰é¡¹
            student_option_found = False
            correct_option_found = False

            for i, option in enumerate(options):
                option_clean = option.strip().lower()
                option_letter = chr(65 + i).lower()  # A, B, C, D

                # æ£€æŸ¥å­¦ç”Ÿç­”æ¡ˆæ˜¯å¦åŒ¹é…æ­¤é€‰é¡¹
                if student_clean == option_clean or student_clean == option_letter:
                    student_option_found = True
                    # æ£€æŸ¥è¿™ä¸ªé€‰é¡¹æ˜¯å¦æ˜¯æ­£ç¡®ç­”æ¡ˆ
                    if correct_clean == option_clean or correct_clean == option_letter:
                        return max_score, max_score

                # æ£€æŸ¥æ­£ç¡®ç­”æ¡ˆæ˜¯å¦åŒ¹é…æ­¤é€‰é¡¹
                if correct_clean == option_clean or correct_clean == option_letter:
                    correct_option_found = True

        return 0.0, max_score

    def _score_short_answer(
        self, question: Dict, student_answer: str, max_score: float
    ) -> Tuple[float, float]:
        """è¯„åˆ†ç®€ç­”é¢˜"""
        correct_answer = question.get("correct_answer", "")

        if not correct_answer.strip():
            # å¦‚æœæ²¡æœ‰æ ‡å‡†ç­”æ¡ˆï¼Œç»™äºˆéƒ¨åˆ†åˆ†æ•°
            return max_score * 0.5, max_score

        # æ£€æŸ¥æ˜¯å¦å¯ç”¨AIè¯„åˆ†
        if self.ai_scoring_enabled and self.api_key:
            # ä½¿ç”¨AIè¿›è¡Œè¯­ä¹‰ç›¸ä¼¼åº¦è¯„åˆ†
            ai_similarity = self._calculate_semantic_similarity(
                student_answer, correct_answer
            )
            print(f"ğŸ¤– AIè¯­ä¹‰ç›¸ä¼¼åº¦è¯„åˆ†: {ai_similarity:.2f}")

            # ä½¿ç”¨å…³é”®è¯åŒ¹é…ä½œä¸ºè¾…åŠ©è¯„åˆ†
            keyword_score = self._simple_keyword_similarity(
                student_answer, correct_answer
            )
            print(f"ğŸ“ å…³é”®è¯åŒ¹é…è¯„åˆ†: {keyword_score:.2f}")

            # AIè¯„åˆ†å 80%ï¼Œå…³é”®è¯åŒ¹é…å 20%
            final_similarity = ai_similarity * 0.8 + keyword_score * 0.2
            print(
                f"âœ… ç®€ç­”é¢˜æœ€ç»ˆè¯„åˆ†: AI{ai_similarity:.2f}*0.8 + å…³é”®è¯{keyword_score:.2f}*0.2 = {final_similarity:.2f}"
            )
        else:
            # AIè¯„åˆ†ç¦ç”¨æˆ–APIä¸å¯ç”¨ï¼Œä½¿ç”¨åŸºæœ¬è¯„åˆ†ç»“æ„
            print("ğŸ“ ä½¿ç”¨åŸºæœ¬è¯„åˆ†ç»“æ„ï¼ˆéAIæ¨¡å¼ï¼‰")

            # åŸºæœ¬è¯„åˆ†ç»“æ„ï¼šå…³é”®è¯åŒ¹é… + é•¿åº¦è¯„åˆ† + åŸºæœ¬é€»è¾‘
            keyword_score = self._simple_keyword_similarity(
                student_answer, correct_answer
            )
            length_score = self._evaluate_answer_length(student_answer, correct_answer)
            basic_logic_score = self._evaluate_basic_logic(student_answer)

            # åŸºæœ¬è¯„åˆ†æƒé‡ï¼šå…³é”®è¯70%ï¼Œé•¿åº¦20%ï¼Œé€»è¾‘10%
            final_similarity = (
                keyword_score * 0.7 + length_score * 0.2 + basic_logic_score * 0.1
            )
            print(
                f"âœ… åŸºæœ¬è¯„åˆ†ç»“æ„: å…³é”®è¯{keyword_score:.2f}*0.7 + é•¿åº¦{length_score:.2f}*0.2 + é€»è¾‘{basic_logic_score:.2f}*0.1 = {final_similarity:.2f}"
            )

            # ç¡®ä¿æœ‰ç­”æ¡ˆå°±æœ‰åŸºæœ¬åˆ†æ•°
            if final_similarity < 0.1 and student_answer.strip():
                final_similarity = 0.1  # æœ‰å†…å®¹å°±è‡³å°‘ç»™10%ç›¸ä¼¼åº¦
                print(f"ğŸ›¡ï¸ åŸºæœ¬è¯„åˆ†ä¿æŠ¤ï¼šç»™äºˆæœ€ä½10%ç›¸ä¼¼åº¦")

        # åŸºäºç›¸ä¼¼åº¦è®¡ç®—åˆ†æ•°ï¼Œä½¿ç”¨æ›´ç»†è‡´çš„åˆ†çº§
        if final_similarity >= 0.9:
            return max_score, max_score
        elif final_similarity >= 0.8:
            return max_score * 0.9, max_score
        elif final_similarity >= 0.7:
            return max_score * 0.8, max_score
        elif final_similarity >= 0.6:
            return max_score * 0.7, max_score
        elif final_similarity >= 0.5:
            return max_score * 0.5, max_score
        elif final_similarity >= 0.3:
            return max_score * 0.3, max_score
        else:
            return 0.0, max_score

    def _score_programming(
        self, question: Dict, student_answer: str, max_score: float
    ) -> Tuple[float, float]:
        """è¯„åˆ†ç¼–ç¨‹é¢˜ - æ”¹è¿›çš„æ­¥éª¤åˆ†è¯„ä¼°"""
        try:
            if not student_answer.strip():
                return 0.0, max_score

            print(f"ğŸ“ å¼€å§‹è¯„åˆ†ç¼–ç¨‹é¢˜ï¼Œæœ€å¤§åˆ†æ•°: {max_score}")

            # åŸºæœ¬é•¿åº¦æ£€æŸ¥ - ç»™æ›´å®½æ¾çš„åˆ¤æ–­
            if len(student_answer.strip()) < 10:
                print(f"âš ï¸ ä»£ç è¿‡çŸ­({len(student_answer.strip())}å­—ç¬¦)ï¼Œç»™åŸºç¡€åˆ†")
                return max_score * 0.1, max_score

            # 1. åŸºç¡€ç»“æ„è¯„åˆ†ï¼ˆå æ¯”30%ï¼‰
            structure_score = self._check_programming_structure(student_answer)
            print(f"ğŸ—ï¸ ç»“æ„è¯„åˆ†: {structure_score:.2f}")

            # 2. è¯­æ³•å’ŒåŸºæœ¬é€»è¾‘è¯„åˆ†ï¼ˆå æ¯”25%ï¼‰
            syntax_score = self._check_syntax_and_logic(student_answer)
            print(f"âš™ï¸ è¯­æ³•é€»è¾‘è¯„åˆ†: {syntax_score:.2f}")

            # 3. æ‰§è¡Œè¯„åˆ†ï¼ˆå æ¯”20%ï¼‰ - ä¸å¼ºåˆ¶è¦æ±‚å®Œç¾è¿è¡Œ
            execution_score = 0.3  # å¦‚æœæœ‰åŸºæœ¬ä»£ç ç»“æ„ï¼Œé»˜è®¤ç»™30%
            try:
                execution_score = self._execute_programming_code(student_answer)
            except Exception as e:
                print(f"âš ï¸ ä»£ç æ‰§è¡Œæ£€æŸ¥å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤åˆ†æ•°: {str(e)}")

            print(f"ğŸš€ æ‰§è¡Œè¯„åˆ†: {execution_score:.2f}")

            # 4. ä½¿ç”¨AIè¯„ä¼°ä»£ç è´¨é‡å’Œç®—æ³•æ€è·¯ï¼ˆå¦‚æœå¯ç”¨ä¸”å¯ç”¨ï¼‰
            if self.ai_scoring_enabled and self.api_key:
                ai_score = self._evaluate_code_with_ai(question, student_answer)
                print(f"ğŸ¤– AIç»¼åˆè¯„åˆ†: {ai_score:.2f}")

                # ç»¼åˆè¯„åˆ†ï¼šAIå 80%ï¼Œç»“æ„10%ï¼Œè¯­æ³•5%ï¼Œæ‰§è¡Œ5%
                final_score = (
                    ai_score * 0.8
                    + structure_score * 0.1
                    + syntax_score * 0.05
                    + execution_score * 0.05
                ) * max_score
                print(
                    f"âœ… AIæ¨¡å¼æœ€ç»ˆè¯„åˆ†: AI{ai_score:.2f}*0.8 + ç»“æ„{structure_score:.2f}*0.1 + è¯­æ³•{syntax_score:.2f}*0.05 + æ‰§è¡Œ{execution_score:.2f}*0.05 = {final_score:.2f}/{max_score}"
                )
            else:
                # AIè¯„åˆ†ç¦ç”¨ï¼Œä½¿ç”¨åŸºæœ¬è¯„åˆ†ç»“æ„
                print("ğŸ“ ä½¿ç”¨åŸºæœ¬è¯„åˆ†ç»“æ„ï¼ˆéAIæ¨¡å¼ï¼‰")

                # åŸºæœ¬è¯„åˆ†ç»“æ„ï¼šç»“æ„40%ï¼Œè¯­æ³•35%ï¼Œæ‰§è¡Œ25%
                final_score = (
                    structure_score * 0.4 + syntax_score * 0.35 + execution_score * 0.25
                ) * max_score
                print(
                    f"âœ… åŸºæœ¬è¯„åˆ†ç»“æ„æœ€ç»ˆè¯„åˆ†: ç»“æ„{structure_score:.2f}*0.4 + è¯­æ³•{syntax_score:.2f}*0.35 + æ‰§è¡Œ{execution_score:.2f}*0.25 = {final_score:.2f}/{max_score}"
                )

                # ç¡®ä¿åŸºæœ¬è¯„åˆ†ç»™äºˆåˆç†åˆ†æ•°
                if final_score < max_score * 0.1 and student_answer.strip():
                    final_score = max_score * 0.1  # æœ‰ä»£ç å†…å®¹å°±è‡³å°‘ç»™10%
                    print(
                        f"ğŸ›¡ï¸ åŸºæœ¬è¯„åˆ†ä¿æŠ¤ï¼šç»™äºˆæœ€ä½10%åˆ†æ•° = {final_score:.2f}/{max_score}"
                    )

            return min(final_score, max_score), max_score

        except Exception as e:
            print(f"âŒ ç¼–ç¨‹é¢˜è¯„åˆ†å¤±è´¥: {str(e)}")
            # ç»™äºˆåŸºç¡€åˆ†æ•° - å¦‚æœæœ‰ä»£ç å°±ç»™30%
            base_score = max_score * 0.3 if student_answer.strip() else 0.0
            return base_score, max_score

    def _calculate_semantic_similarity(self, text1: str, text2: str) -> float:
        """è®¡ç®—è¯­ä¹‰ç›¸ä¼¼åº¦"""
        try:
            # æ£€æŸ¥AIè¯„åˆ†æ˜¯å¦å¯ç”¨
            if not self.ai_scoring_enabled or not self.api_key:
                return self._simple_keyword_similarity(text1, text2)

            # ä½¿ç”¨AI APIè®¡ç®—è¯­ä¹‰ç›¸ä¼¼åº¦
            prompt = f"""
è¯·æ¯”è¾ƒä»¥ä¸‹ä¸¤ä¸ªæ–‡æœ¬çš„è¯­ä¹‰ç›¸ä¼¼åº¦ï¼Œè¿”å›0-1ä¹‹é—´çš„åˆ†æ•°ï¼ˆ1è¡¨ç¤ºå®Œå…¨ç›¸åŒï¼Œ0è¡¨ç¤ºå®Œå…¨ä¸åŒï¼‰ï¼š

æ–‡æœ¬1ï¼š{text1}
æ–‡æœ¬2ï¼š{text2}

è¯·åªè¿”å›ä¸€ä¸ªæ•°å­—åˆ†æ•°ï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚
"""

            response = self._call_ai_api(prompt)
            if response:
                # å°è¯•æå–æ•°å­—
                import re

                numbers = re.findall(r"0\.\d+|1\.0|0|1", response)
                if numbers:
                    return float(numbers[0])

            # å¦‚æœAIè°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨ç®€å•çš„å…³é”®è¯åŒ¹é…
            return self._simple_keyword_similarity(text1, text2)

        except Exception as e:
            print(f"è¯­ä¹‰ç›¸ä¼¼åº¦è®¡ç®—å¤±è´¥: {str(e)}")
            return self._simple_keyword_similarity(text1, text2)

    def _simple_keyword_similarity(self, text1: str, text2: str) -> float:
        """ç®€å•çš„å…³é”®è¯ç›¸ä¼¼åº¦è®¡ç®—"""
        words1 = set(text1.lower().split())
        words2 = set(text2.lower().split())

        if not words1 or not words2:
            return 0.0

        intersection = words1.intersection(words2)
        union = words1.union(words2)

        return len(intersection) / len(union)

    def _evaluate_answer_length(
        self, student_answer: str, correct_answer: str
    ) -> float:
        """è¯„ä¼°ç­”æ¡ˆé•¿åº¦çš„åˆç†æ€§"""
        if not student_answer.strip():
            return 0.0

        student_len = len(student_answer.strip())
        correct_len = (
            len(correct_answer.strip()) if correct_answer else 50
        )  # é»˜è®¤æœŸæœ›é•¿åº¦

        # é•¿åº¦æ¯”ä¾‹è¯„åˆ†
        if correct_len == 0:
            return 0.5 if student_len > 10 else 0.2

        ratio = student_len / correct_len
        if 0.5 <= ratio <= 2.0:  # é•¿åº¦åœ¨æ ‡å‡†ç­”æ¡ˆçš„50%-200%ä¹‹é—´
            return 1.0
        elif 0.3 <= ratio < 0.5 or 2.0 < ratio <= 3.0:  # ç¨çŸ­æˆ–ç¨é•¿
            return 0.7
        elif 0.1 <= ratio < 0.3 or 3.0 < ratio <= 5.0:  # å¤ªçŸ­æˆ–å¤ªé•¿
            return 0.4
        else:
            return 0.2

    def _evaluate_basic_logic(self, student_answer: str) -> float:
        """è¯„ä¼°ç­”æ¡ˆçš„åŸºæœ¬é€»è¾‘æ€§"""
        if not student_answer.strip():
            return 0.0

        score = 0.0
        text = student_answer.lower()

        # æ£€æŸ¥é€»è¾‘è¿æ¥è¯
        logic_words = [
            "å› ä¸º",
            "æ‰€ä»¥",
            "ç”±äº",
            "å› æ­¤",
            "ç„¶è€Œ",
            "ä½†æ˜¯",
            "é¦–å…ˆ",
            "å…¶æ¬¡",
            "æœ€å",
            "ä¾‹å¦‚",
            "æ¯”å¦‚",
            "æ€»ä¹‹",
            "ç»¼ä¸Š",
            "therefore",
            "because",
            "however",
            "first",
        ]

        logic_count = sum(1 for word in logic_words if word in text)
        score += min(logic_count * 0.2, 0.5)  # é€»è¾‘è¯æœ€å¤šåŠ 0.5åˆ†

        # æ£€æŸ¥å¥å­å®Œæ•´æ€§ï¼ˆæ˜¯å¦æœ‰æ ‡ç‚¹ç¬¦å·ï¼‰
        punctuation = ["ã€‚", "ï¼", "ï¼Ÿ", ".", "!", "?"]
        if any(p in student_answer for p in punctuation):
            score += 0.3

        # æ£€æŸ¥æ˜¯å¦æœ‰åŸºæœ¬ç»“æ„ï¼ˆå¤šä¸ªå¥å­ï¼‰
        sentences = len([s for s in student_answer.split("ã€‚") if s.strip()]) + len(
            [s for s in student_answer.split(".") if s.strip()]
        )
        if sentences > 1:
            score += 0.2

        return min(score, 1.0)

    def _update_answer_scores(
        self, exam_or_instance_id: int, question_scores: list, is_instance: bool = False
    ):
        """æ›´æ–°æ•°æ®åº“ä¸­çš„Answerè®°å½•åˆ†æ•°"""
        try:
            # å¯¼å…¥è¿™é‡Œè€Œä¸æ˜¯åœ¨æ–‡ä»¶é¡¶éƒ¨ï¼Œé¿å…å¾ªç¯å¯¼å…¥
            from flask import has_app_context
            from models import Answer, db

            # æ£€æŸ¥æ˜¯å¦åœ¨åº”ç”¨ä¸Šä¸‹æ–‡ä¸­
            if not has_app_context():
                print("âš ï¸ ä¸åœ¨Flaskåº”ç”¨ä¸Šä¸‹æ–‡ä¸­ï¼Œæ— æ³•æ›´æ–°ç­”æ¡ˆåˆ†æ•°")
                return

            print(f"ğŸ”„ å¼€å§‹æ›´æ–°ç­”æ¡ˆåˆ†æ•°åˆ°æ•°æ®åº“...")

            updated_count = 0
            for q_score in question_scores:
                question_id = q_score["question_id"]
                score = q_score["score"]
                max_score = q_score["max_score"]

                # æ ¹æ®æ˜¯æ–°ç³»ç»Ÿè¿˜æ˜¯æ—§ç³»ç»ŸæŸ¥æ‰¾ç­”æ¡ˆè®°å½•
                if is_instance:
                    # æ–°ç³»ç»Ÿï¼šé€šè¿‡exam_instance_idæŸ¥æ‰¾
                    answer = Answer.query.filter_by(
                        exam_instance_id=exam_or_instance_id, question_id=question_id
                    ).first()
                else:
                    # æ—§ç³»ç»Ÿï¼šé€šè¿‡exam_idæŸ¥æ‰¾
                    answer = Answer.query.filter_by(
                        exam_id=exam_or_instance_id, question_id=question_id
                    ).first()

                if answer:
                    # æ›´æ–°åˆ†æ•°å’Œæ­£ç¡®æ€§
                    old_score = answer.score
                    answer.score = round(score, 2)
                    answer.is_correct = score >= max_score * 0.8  # 80%ä»¥ä¸Šç®—æ­£ç¡®

                    if old_score != answer.score:
                        print(f"ğŸ“ æ›´æ–°é¢˜ç›®{question_id}: {old_score} â†’ {answer.score}")
                        updated_count += 1
                else:
                    print(f"âš ï¸ æœªæ‰¾åˆ°é¢˜ç›®{question_id}çš„ç­”æ¡ˆè®°å½•")

            # æäº¤åˆ°æ•°æ®åº“
            db.session.commit()
            print(f"âœ… æˆåŠŸæ›´æ–°{updated_count}ä¸ªç­”æ¡ˆçš„åˆ†æ•°åˆ°æ•°æ®åº“")

        except Exception as e:
            print(f"âŒ æ›´æ–°ç­”æ¡ˆåˆ†æ•°å¤±è´¥: {str(e)}")
            try:
                from models import db

                db.session.rollback()
            except:
                pass

    def _check_programming_structure(self, code: str) -> float:
        """æ£€æŸ¥ç¼–ç¨‹ä»£ç çš„åŸºæœ¬ç»“æ„"""
        score = 0.0
        code_lower = code.lower()

        # æ£€æŸ¥åŸºæœ¬Pythonç»“æ„
        structure_checks = [
            ("def ", 0.2),  # å‡½æ•°å®šä¹‰
            ("class ", 0.1),  # ç±»å®šä¹‰
            ("if ", 0.15),  # æ¡ä»¶è¯­å¥
            ("for ", 0.1),  # å¾ªç¯
            ("while ", 0.1),  # å¾ªç¯
            ("import ", 0.05),  # å¯¼å…¥
            ("return ", 0.1),  # è¿”å›è¯­å¥
            ("print(", 0.05),  # è¾“å‡ºè¯­å¥
            ("=", 0.1),  # èµ‹å€¼
            (":", 0.05),  # å†’å·ï¼ˆç»“æ„æ ‡å¿—ï¼‰
        ]

        for pattern, weight in structure_checks:
            if pattern in code_lower:
                score += weight

        # æ£€æŸ¥ä»£ç ç¼©è¿›ï¼ˆåŸºæœ¬æ ¼å¼æ£€æŸ¥ï¼‰
        lines = code.split("\n")
        has_indentation = any(
            line.startswith("    ") or line.startswith("\t") for line in lines
        )
        if has_indentation:
            score += 0.1

        return min(score, 1.0)

    def _check_syntax_and_logic(self, code: str) -> float:
        """æ£€æŸ¥è¯­æ³•å’ŒåŸºæœ¬é€»è¾‘"""
        score = 0.0

        try:
            # 1. è¯­æ³•æ£€æŸ¥
            compile(code, "<string>", "exec")
            score += 0.5  # è¯­æ³•æ­£ç¡®ç»™50%
            print("âœ… è¯­æ³•æ£€æŸ¥é€šè¿‡")
        except SyntaxError as e:
            print(f"âš ï¸ è¯­æ³•é”™è¯¯: {str(e)}")
            score += 0.1  # è¯­æ³•é”™è¯¯ä½†æœ‰ä»£ç ç»“æ„ç»™10%
        except Exception as e:
            print(f"âš ï¸ ç¼–è¯‘é”™è¯¯: {str(e)}")
            score += 0.2  # å…¶ä»–ç¼–è¯‘é—®é¢˜ç»™20%

        # 2. åŸºæœ¬é€»è¾‘ç»“æ„æ£€æŸ¥
        code_lower = code.lower()
        logic_patterns = [
            ("if", 0.1),  # æ¡ä»¶åˆ¤æ–­
            ("else", 0.05),  # æ¡ä»¶åˆ†æ”¯
            ("for", 0.1),  # å¾ªç¯
            ("while", 0.1),  # å¾ªç¯
            ("def", 0.15),  # å‡½æ•°å®šä¹‰
            ("return", 0.1),  # è¿”å›å€¼
        ]

        for pattern, weight in logic_patterns:
            if pattern in code_lower:
                score += weight
                print(f"âœ… å‘ç°é€»è¾‘ç»“æ„: {pattern}")

        return min(score, 1.0)

    def _evaluate_code_with_ai(self, question: Dict, code: str) -> float:
        """ä½¿ç”¨AIè¯„ä¼°ä»£ç è´¨é‡å’Œç®—æ³•æ€è·¯"""
        try:
            if not self.ai_scoring_enabled or not self.api_key:
                return 0.5  # ä¸ä½¿ç”¨AIæ—¶è¿”å›ä¸­ç­‰åˆ†æ•°

            question_content = question.get("content", "ç¼–ç¨‹é¢˜ç›®")
            correct_answer = question.get("correct_answer", "")

            prompt = f"""
è¯·è¯„ä¼°ä»¥ä¸‹Pythonä»£ç çš„è´¨é‡ï¼Œé‡ç‚¹å…³æ³¨æ­¥éª¤åˆ†å’Œéƒ¨åˆ†åˆ†æ•°ï¼š

é¢˜ç›®ï¼š{question_content}
å‚è€ƒç­”æ¡ˆï¼š{correct_answer}
å­¦ç”Ÿä»£ç ï¼š{code}

è¯„ä¼°æ ‡å‡†ï¼š
1. ç®—æ³•æ€è·¯æ­£ç¡®æ€§ (40%) - å³ä½¿ä»£ç ä¸å®Œæ•´ï¼Œæ€è·¯å¯¹å°±ç»™åˆ†
2. ä»£ç ç»“æ„åˆç†æ€§ (30%) - å˜é‡å‘½åã€å‡½æ•°ç»“æ„ç­‰
3. æ ¸å¿ƒé€»è¾‘å®ç° (20%) - å…³é”®ä»£ç è¯­å¥æ˜¯å¦æ­£ç¡®
4. ä»£ç å®Œæ•´æ€§ (10%) - æ˜¯å¦å®Œæ•´å®ç°

ç‰¹åˆ«æ³¨æ„ï¼š
- å¦‚æœæ ¸å¿ƒç®—æ³•æ€è·¯æ­£ç¡®ï¼Œå³ä½¿ä»£ç ä¸èƒ½è¿è¡Œä¹Ÿåº”è¯¥ç»™è¾ƒé«˜åˆ†æ•°
- å¦‚æœæœ‰éƒ¨åˆ†æ­£ç¡®çš„ä»£ç è¯­å¥ï¼Œåº”è¯¥ç»™å¯¹åº”çš„éƒ¨åˆ†åˆ†æ•°
- ä¸è¦å› ä¸ºä»£ç ä¸å®Œæ•´å°±ç»™å¾ˆä½åˆ†æ•°

è¯·è¿”å›0-1ä¹‹é—´çš„åˆ†æ•°ï¼Œä»£è¡¨è¯¥ä»£ç åº”è¯¥å¾—åˆ°çš„ç™¾åˆ†æ¯”åˆ†æ•°ã€‚
åªè¿”å›æ•°å­—ï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚
"""

            response = self._call_ai_api(prompt)
            if response:
                # å°è¯•æå–æ•°å­—
                import re

                numbers = re.findall(r"0\.\d+|1\.0|0|1", response)
                if numbers:
                    ai_score = float(numbers[0])
                    print(f"ğŸ¤– AIè¯„åˆ†è¯¦æƒ…: {ai_score}")
                    return ai_score

            # å¦‚æœAIè°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨åŸºç¡€è¯„åˆ†
            return 0.5

        except Exception as e:
            print(f"âŒ AIä»£ç è¯„ä¼°å¤±è´¥: {str(e)}")
            return 0.5

    def _execute_programming_code(self, code: str) -> float:
        """æ‰§è¡Œç¼–ç¨‹ä»£ç å¹¶è¯„åˆ†ï¼ˆå®‰å…¨æ£€æŸ¥ï¼‰"""
        try:
            # å®‰å…¨æ£€æŸ¥ï¼šç¦æ­¢å±é™©æ“ä½œ
            dangerous_patterns = [
                "import os",
                "import sys",
                "import subprocess",
                "import shutil",
                "open(",
                "file(",
                "exec(",
                "eval(",
                "__import__",
                "getattr",
                "setattr",
                "delattr",
                "globals(",
                "locals(",
                "input(",
                "raw_input(",
            ]

            code_lower = code.lower()
            for pattern in dangerous_patterns:
                if pattern in code_lower:
                    print(f"æ£€æµ‹åˆ°æ½œåœ¨å±é™©ä»£ç : {pattern}")
                    return 0.3  # ç»™äºˆä½åˆ†ä½†ä¸æ˜¯é›¶åˆ†

            # ç®€å•çš„è¯­æ³•æ£€æŸ¥
            try:
                compile(code, "<string>", "exec")
                syntax_score = 1.0
            except SyntaxError as e:
                print(f"è¯­æ³•é”™è¯¯: {str(e)}")
                syntax_score = 0.2
            except Exception as e:
                print(f"ç¼–è¯‘é”™è¯¯: {str(e)}")
                syntax_score = 0.4

            # å¦‚æœè¯­æ³•æ­£ç¡®ï¼Œå°è¯•æœ‰é™æ‰§è¡Œï¼ˆåœ¨æ²™ç›’ç¯å¢ƒä¸­ï¼‰
            if syntax_score >= 1.0:
                try:
                    # åˆ›å»ºå—é™çš„æ‰§è¡Œç¯å¢ƒ
                    restricted_globals = {
                        "__builtins__": {
                            "len": len,
                            "str": str,
                            "int": int,
                            "float": float,
                            "list": list,
                            "dict": dict,
                            "tuple": tuple,
                            "range": range,
                            "enumerate": enumerate,
                            "min": min,
                            "max": max,
                            "sum": sum,
                            "abs": abs,
                            "round": round,
                            "print": print,
                        }
                    }

                    # é™åˆ¶æ‰§è¡Œæ—¶é—´å’Œè¾“å‡º
                    exec(code, restricted_globals, {})
                    return 1.0  # æ‰§è¡ŒæˆåŠŸ

                except Exception as e:
                    print(f"è¿è¡Œæ—¶é”™è¯¯: {str(e)}")
                    return 0.6  # è¯­æ³•æ­£ç¡®ä½†è¿è¡Œå¤±è´¥

            return syntax_score

        except Exception as e:
            print(f"ä»£ç è¯„ä¼°å¤±è´¥: {str(e)}")
            return 0.5  # ç»™äºˆä¸­ç­‰åˆ†æ•°

    def _evaluate_code_quality(self, question: Dict, code: str) -> float:
        """è¯„ä¼°ä»£ç è´¨é‡"""
        try:
            # æ£€æŸ¥AIè¯„åˆ†æ˜¯å¦å¯ç”¨
            if not self.ai_scoring_enabled or not self.api_key:
                return 0.5  # ä¸ä½¿ç”¨AIæ—¶è¿”å›ä¸­ç­‰åˆ†æ•°

            prompt = f"""
è¯·è¯„ä¼°ä»¥ä¸‹Pythonä»£ç çš„è´¨é‡ï¼Œè€ƒè™‘ä»¥ä¸‹æ–¹é¢ï¼š
1. ä»£ç æ­£ç¡®æ€§
2. ä»£ç é£æ ¼å’Œå¯è¯»æ€§
3. ç®—æ³•æ•ˆç‡
4. é”™è¯¯å¤„ç†

é¢˜ç›®è¦æ±‚ï¼š{question.get('content', '')}
å­¦ç”Ÿä»£ç ï¼š{code}

è¯·è¿”å›0-1ä¹‹é—´çš„åˆ†æ•°ï¼ˆ1è¡¨ç¤ºä¼˜ç§€ï¼Œ0è¡¨ç¤ºå¾ˆå·®ï¼‰ã€‚
åªè¿”å›æ•°å­—åˆ†æ•°ï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚
"""

            response = self._call_ai_api(prompt)
            if response:
                import re

                numbers = re.findall(r"0\.\d+|1\.0|0|1", response)
                if numbers:
                    return float(numbers[0])

            return 0.5  # é»˜è®¤ä¸­ç­‰åˆ†æ•°

        except Exception as e:
            print(f"ä»£ç è´¨é‡è¯„ä¼°å¤±è´¥: {str(e)}")
            return 0.5

    def _call_ai_api(self, prompt: str) -> str:
        """è°ƒç”¨AI API"""
        try:
            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json",
            }

            data = {
                "model": self.model,
                "messages": [
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä»£ç è¯„å®¡ä¸“å®¶ï¼Œè¯·ä¸¥æ ¼æŒ‰ç…§è¦æ±‚è¿”å›ç»“æœã€‚",
                    },
                    {"role": "user", "content": prompt},
                ],
                "temperature": 0.3,
                "max_tokens": 100,
            }

            response = requests.post(
                self.api_url, headers=headers, json=data, timeout=30
            )

            if response.status_code == 200:
                result = response.json()
                return result["choices"][0]["message"]["content"]
            else:
                print(f"AI APIè°ƒç”¨å¤±è´¥: {response.status_code}")
                return None

        except Exception as e:
            print(f"AI APIè°ƒç”¨å¼‚å¸¸: {str(e)}")
            return None

    def _calculate_grade(self, percentage: float) -> str:
        """è®¡ç®—ç­‰çº§"""
        if percentage >= 90:
            return "A+"
        elif percentage >= 85:
            return "A"
        elif percentage >= 80:
            return "A-"
        elif percentage >= 75:
            return "B+"
        elif percentage >= 70:
            return "B"
        elif percentage >= 65:
            return "B-"
        elif percentage >= 60:
            return "C+"
        elif percentage >= 55:
            return "C"
        elif percentage >= 50:
            return "C-"
        else:
            return "F"

    def _generate_summary(
        self, percentage: float, subject_scores: Dict[str, float]
    ) -> str:
        """ç”Ÿæˆæˆç»©æ€»ç»“"""
        if percentage >= 80:
            performance = "ä¼˜ç§€"
        elif percentage >= 70:
            performance = "è‰¯å¥½"
        elif percentage >= 60:
            performance = "åŠæ ¼"
        else:
            performance = "éœ€è¦æ”¹è¿›"

        # æ‰¾å‡ºæœ€å¼ºå’Œæœ€å¼±çš„å­¦ç§‘
        if subject_scores:
            best_subject = max(subject_scores.items(), key=lambda x: x[1])
            worst_subject = min(subject_scores.items(), key=lambda x: x[1])

            return f"æ€»ä½“è¡¨ç°{performance}ã€‚åœ¨{best_subject[0]}æ–¹é¢è¡¨ç°æœ€ä½³({best_subject[1]:.1f}%)ï¼Œåœ¨{worst_subject[0]}æ–¹é¢éœ€è¦åŠ å¼º({worst_subject[1]:.1f}%)ã€‚"
        else:
            return f"æ€»ä½“è¡¨ç°{performance}ã€‚"
